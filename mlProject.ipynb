{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjwdhkpZJ50Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello worrld\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ПРОЕКТ: Классификация спам-писем с использованием машинного обучения\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка визуализации\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ПРОЕКТ: Классификация спам-писем\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nБиблиотеки успешно импортированы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ПРЕЗЕНТАЦИЯ ПРОЕКТА\n",
    "\n",
    "## Название проекта\n",
    "**Классификация спам-писем с использованием машинного обучения**\n",
    "\n",
    "## Цель проекта\n",
    "Разработать модель машинного обучения, которая с точностью выше 95% классифицирует входящие электронные письма как спам или не-спам (ham), автоматизируя процесс фильтрации нежелательной почты.\n",
    "\n",
    "## Задачи проекта\n",
    "1. Загрузить и изучить датасет электронных писем\n",
    "2. Провести разведочный анализ данных (EDA) и визуализацию\n",
    "3. Выполнить препроцессинг текстовых данных (очистка, токенизация, векторизация)\n",
    "4. Обучить несколько моделей классификации (Логистическая регрессия, Random Forest, XGBoost)\n",
    "5. Сравнить модели по ключевым метрикам (Accuracy, Precision, Recall, F1-Score, ROC AUC)\n",
    "6. Выбрать лучшую модель и проанализировать важность признаков\n",
    "7. Визуализировать результаты (Confusion Matrix, ROC-кривая)\n",
    "\n",
    "## Актуальность\n",
    "Фильтрация спама критически важна для:\n",
    "- **Безопасности пользователей**: защита от фишинга и мошенничества\n",
    "- **Производительности**: экономия времени на обработке нежелательной почты\n",
    "- **Экономики**: снижение затрат на хранение и обработку спама (миллиарды долларов ежегодно)\n",
    "- **UX**: улучшение пользовательского опыта при работе с почтой\n",
    "\n",
    "Современные почтовые системы обрабатывают миллиарды писем ежедневно, и автоматическая классификация спама является неотъемлемой частью инфраструктуры электронной почты.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ДАТАСЕТ (Dataset)\n",
    "\n",
    "## Источник данных\n",
    "Датасет `emails.csv` содержит коллекцию электронных писем с метками спам/не-спам.\n",
    "\n",
    "## Описание набора данных\n",
    "Давайте загрузим и изучим датасет:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета\n",
    "df = pd.read_csv('data/emails.csv')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ИНФОРМАЦИЯ О ДАТАСЕТЕ\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nРазмер датасета: {df.shape[0]} строк, {df.shape[1]} столбцов\")\n",
    "print(f\"\\nКолонки: {df.columns.tolist()}\")\n",
    "print(f\"\\nТипы данных:\\n{df.dtypes}\")\n",
    "print(f\"\\nПропущенные значения:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nДубликаты: {df.duplicated().sum()}\")\n",
    "\n",
    "# Распределение классов\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"РАСПРЕДЕЛЕНИЕ КЛАССОВ\")\n",
    "print(\"=\" * 80)\n",
    "print(df['spam'].value_counts())\n",
    "print(f\"\\nПроцентное соотношение:\")\n",
    "print(df['spam'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Примеры данных\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ПРИМЕРЫ ДАННЫХ\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nПервые 3 записи:\")\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация распределения классов\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Столбчатая диаграмма\n",
    "df['spam'].value_counts().plot(kind='bar', ax=axes[0], color=['skyblue', 'coral'])\n",
    "axes[0].set_title('Распределение классов (Spam vs Ham)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Класс (0=Ham, 1=Spam)', fontsize=12)\n",
    "axes[0].set_ylabel('Количество', fontsize=12)\n",
    "axes[0].set_xticklabels(['Ham (Не спам)', 'Spam'], rotation=0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Круговая диаграмма\n",
    "df['spam'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
    "                                labels=['Ham (Не спам)', 'Spam'],\n",
    "                                colors=['skyblue', 'coral'], startangle=90)\n",
    "axes[1].set_title('Процентное распределение классов', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nВывод: Датасет содержит {df.shape[0]} писем, из которых:\")\n",
    "print(f\"  - {df[df['spam']==0].shape[0]} ({df[df['spam']==0].shape[0]/df.shape[0]*100:.1f}%) - Ham (не спам)\")\n",
    "print(f\"  - {df[df['spam']==1].shape[0]} ({df[df['spam']==1].shape[0]/df.shape[0]*100:.1f}%) - Spam\")\n",
    "print(f\"\\nДатасет несбалансирован, что потребует внимания при обучении моделей.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ПРЕПРОЦЕССИНГ (Preprocessing) И EDA\n",
    "\n",
    "## 3.1 Анализ длины текстов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ длины текстов\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df['word_count'] = df['text'].str.split().str.len()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"СТАТИСТИКА ПО ДЛИНЕ ТЕКСТОВ\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nОбщая статистика:\")\n",
    "print(df[['text_length', 'word_count']].describe())\n",
    "\n",
    "print(\"\\n\\nСтатистика по классам:\")\n",
    "print(df.groupby('spam')[['text_length', 'word_count']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация длины текстов\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Распределение длины текста\n",
    "axes[0, 0].hist(df[df['spam']==0]['text_length'], bins=50, alpha=0.7, label='Ham', color='skyblue')\n",
    "axes[0, 0].hist(df[df['spam']==1]['text_length'], bins=50, alpha=0.7, label='Spam', color='coral')\n",
    "axes[0, 0].set_title('Распределение длины текста (символы)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Длина текста (символы)')\n",
    "axes[0, 0].set_ylabel('Частота')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Распределение количества слов\n",
    "axes[0, 1].hist(df[df['spam']==0]['word_count'], bins=50, alpha=0.7, label='Ham', color='skyblue')\n",
    "axes[0, 1].hist(df[df['spam']==1]['word_count'], bins=50, alpha=0.7, label='Spam', color='coral')\n",
    "axes[0, 1].set_title('Распределение количества слов', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Количество слов')\n",
    "axes[0, 1].set_ylabel('Частота')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Boxplot длины текста\n",
    "df_box = pd.melt(df, id_vars=['spam'], value_vars=['text_length'], \n",
    "                 var_name='metric', value_name='value')\n",
    "df_box['spam_label'] = df_box['spam'].map({0: 'Ham', 1: 'Spam'})\n",
    "sns.boxplot(data=df_box, x='spam_label', y='value', ax=axes[1, 0], palette=['skyblue', 'coral'])\n",
    "axes[1, 0].set_title('Boxplot: Длина текста по классам', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Класс')\n",
    "axes[1, 0].set_ylabel('Длина текста (символы)')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Boxplot количества слов\n",
    "df_box2 = pd.melt(df, id_vars=['spam'], value_vars=['word_count'], \n",
    "                  var_name='metric', value_name='value')\n",
    "df_box2['spam_label'] = df_box2['spam'].map({0: 'Ham', 1: 'Spam'})\n",
    "sns.boxplot(data=df_box2, x='spam_label', y='value', ax=axes[1, 1], palette=['skyblue', 'coral'])\n",
    "axes[1, 1].set_title('Boxplot: Количество слов по классам', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Класс')\n",
    "axes[1, 1].set_ylabel('Количество слов')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Очистка и препроцессинг текстовых данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Очистка текста: удаление лишних символов, приведение к нижнему регистру\n",
    "    \"\"\"\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Удаление URL\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Удаление email адресов\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Удаление лишних пробелов\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Удаление пунктуации (опционально, можно оставить для некоторых моделей)\n",
    "    # text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Применяем очистку\n",
    "print(\"Очистка текстов...\")\n",
    "df['text_cleaned'] = df['text'].apply(clean_text)\n",
    "\n",
    "print(\"Примеры очищенных текстов:\")\n",
    "print(\"\\nОригинал (первые 200 символов):\")\n",
    "print(df['text'].iloc[0][:200])\n",
    "print(\"\\nОчищенный (первые 200 символов):\")\n",
    "print(df['text_cleaned'].iloc[0][:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Векторизация текста (TF-IDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF векторизация\n",
    "# Используем параметры, которые хорошо работают для спам-детекции\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,        # Ограничиваем количество признаков для производительности\n",
    "    min_df=2,                  # Минимальная частота слова в документах\n",
    "    max_df=0.95,               # Максимальная частота слова (игнорируем слишком частые)\n",
    "    ngram_range=(1, 2),        # Используем униграммы и биграммы\n",
    "    stop_words='english'       # Удаляем стоп-слова\n",
    ")\n",
    "\n",
    "print(\"Векторизация текстов с помощью TF-IDF...\")\n",
    "X = vectorizer.fit_transform(df['text_cleaned'])\n",
    "y = df['spam'].values\n",
    "\n",
    "print(f\"\\nРазмерность матрицы признаков: {X.shape}\")\n",
    "print(f\"Количество признаков: {X.shape[1]}\")\n",
    "print(f\"Количество образцов: {X.shape[0]}\")\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nРазмер обучающей выборки: {X_train.shape[0]}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape[0]}\")\n",
    "print(f\"\\nРаспределение классов в обучающей выборке:\")\n",
    "print(f\"  Ham: {np.sum(y_train == 0)} ({np.sum(y_train == 0)/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  Spam: {np.sum(y_train == 1)} ({np.sum(y_train == 1)/len(y_train)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. АРХИТЕКТУРА МОДЕЛЕЙ\n",
    "\n",
    "## Выбранные модели\n",
    "\n",
    "Для задачи классификации спама мы обучим следующие модели:\n",
    "\n",
    "1. **Логистическая регрессия** - базовая линейная модель, быстрая и интерпретируемая\n",
    "2. **Random Forest** - ансамблевая модель на основе деревьев решений, хорошо работает с текстовыми данными\n",
    "3. **XGBoost** - градиентный бустинг, часто показывает лучшие результаты на структурированных данных\n",
    "\n",
    "**Почему эти модели?**\n",
    "- Логистическая регрессия: простая, быстрая, хорошая базовая модель для текстовых данных\n",
    "- Random Forest: устойчива к переобучению, хорошо обрабатывает нелинейные зависимости\n",
    "- XGBoost: мощный алгоритм, часто показывает лучшие результаты в соревнованиях\n",
    "\n",
    "Для текстовых данных эти модели работают эффективно после TF-IDF векторизации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ОБУЧЕНИЕ МОДЕЛЕЙ\n",
    "\n",
    "## 5.1 Логистическая регрессия\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "# Логистическая регрессия\n",
    "print(\"=\" * 80)\n",
    "print(\"ОБУЧЕНИЕ: ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_train_time = time.time() - start_time\n",
    "\n",
    "# Предсказания\n",
    "lr_y_pred = lr_model.predict(X_test)\n",
    "lr_y_pred_proba = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "lr_accuracy = accuracy_score(y_test, lr_y_pred)\n",
    "lr_precision = precision_score(y_test, lr_y_pred)\n",
    "lr_recall = recall_score(y_test, lr_y_pred)\n",
    "lr_f1 = f1_score(y_test, lr_y_pred)\n",
    "lr_roc_auc = roc_auc_score(y_test, lr_y_pred_proba)\n",
    "\n",
    "print(f\"\\nВремя обучения: {lr_train_time:.2f} секунд\")\n",
    "print(f\"\\nМЕТРИКИ НА ТЕСТОВОЙ ВЫБОРКЕ:\")\n",
    "print(f\"  Accuracy:  {lr_accuracy:.4f}\")\n",
    "print(f\"  Precision: {lr_precision:.4f}\")\n",
    "print(f\"  Recall:    {lr_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {lr_f1:.4f}\")\n",
    "print(f\"  ROC AUC:   {lr_roc_auc:.4f}\")\n",
    "\n",
    "# Кросс-валидация\n",
    "lr_cv_scores = cross_val_score(lr_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"\\nКросс-валидация (5-fold) Accuracy: {lr_cv_scores.mean():.4f} (+/- {lr_cv_scores.std()*2:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ОБУЧЕНИЕ: RANDOM FOREST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_train_time = time.time() - start_time\n",
    "\n",
    "# Предсказания\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "rf_y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "rf_precision = precision_score(y_test, rf_y_pred)\n",
    "rf_recall = recall_score(y_test, rf_y_pred)\n",
    "rf_f1 = f1_score(y_test, rf_y_pred)\n",
    "rf_roc_auc = roc_auc_score(y_test, rf_y_pred_proba)\n",
    "\n",
    "print(f\"\\nВремя обучения: {rf_train_time:.2f} секунд\")\n",
    "print(f\"\\nМЕТРИКИ НА ТЕСТОВОЙ ВЫБОРКЕ:\")\n",
    "print(f\"  Accuracy:  {rf_accuracy:.4f}\")\n",
    "print(f\"  Precision: {rf_precision:.4f}\")\n",
    "print(f\"  Recall:    {rf_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {rf_f1:.4f}\")\n",
    "print(f\"  ROC AUC:   {rf_roc_auc:.4f}\")\n",
    "\n",
    "# Кросс-валидация\n",
    "rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"\\nКросс-валидация (5-fold) Accuracy: {rf_cv_scores.mean():.4f} (+/- {rf_cv_scores.std()*2:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ОБУЧЕНИЕ: XGBOOST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]),  # Балансировка классов\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_train_time = time.time() - start_time\n",
    "\n",
    "# Предсказания\n",
    "xgb_y_pred = xgb_model.predict(X_test)\n",
    "xgb_y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "xgb_precision = precision_score(y_test, xgb_y_pred)\n",
    "xgb_recall = recall_score(y_test, xgb_y_pred)\n",
    "xgb_f1 = f1_score(y_test, xgb_y_pred)\n",
    "xgb_roc_auc = roc_auc_score(y_test, xgb_y_pred_proba)\n",
    "\n",
    "print(f\"\\nВремя обучения: {xgb_train_time:.2f} секунд\")\n",
    "print(f\"\\nМЕТРИКИ НА ТЕСТОВОЙ ВЫБОРКЕ:\")\n",
    "print(f\"  Accuracy:  {xgb_accuracy:.4f}\")\n",
    "print(f\"  Precision: {xgb_precision:.4f}\")\n",
    "print(f\"  Recall:    {xgb_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {xgb_f1:.4f}\")\n",
    "print(f\"  ROC AUC:   {xgb_roc_auc:.4f}\")\n",
    "\n",
    "# Кросс-валидация\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"\\nКросс-валидация (5-fold) Accuracy: {xgb_cv_scores.mean():.4f} (+/- {xgb_cv_scores.std()*2:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. СРАВНЕНИЕ МОДЕЛЕЙ\n",
    "\n",
    "## 6.1 Сводная таблица результатов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание сводной таблицы результатов\n",
    "results_df = pd.DataFrame({\n",
    "    'Модель': ['Логистическая регрессия', 'Random Forest', 'XGBoost'],\n",
    "    'Accuracy': [lr_accuracy, rf_accuracy, xgb_accuracy],\n",
    "    'Precision': [lr_precision, rf_precision, xgb_precision],\n",
    "    'Recall': [lr_recall, rf_recall, xgb_recall],\n",
    "    'F1-Score': [lr_f1, rf_f1, xgb_f1],\n",
    "    'ROC AUC': [lr_roc_auc, rf_roc_auc, xgb_roc_auc],\n",
    "    'Время обучения (сек)': [lr_train_time, rf_train_time, xgb_train_time]\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"СВОДНАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Визуализация сравнения метрик\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC', 'Время обучения (сек)']\n",
    "models = ['Логистическая\\nрегрессия', 'Random Forest', 'XGBoost']\n",
    "colors = ['skyblue', 'coral', 'lightgreen']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    values = results_df[metric].values\n",
    "    bars = ax.bar(models, values, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Добавляем значения на столбцы\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{value:.4f}' if metric != 'Время обучения (сек)' else f'{value:.2f}с',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax.set_title(metric, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Значение' if metric != 'Время обучения (сек)' else 'Секунды')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_ylim(0, max(values) * 1.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Определение лучшей модели\n",
    "best_model_name = results_df.loc[results_df['F1-Score'].idxmax(), 'Модель']\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ЛУЧШАЯ МОДЕЛЬ: {best_model_name}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  F1-Score: {results_df.loc[results_df['F1-Score'].idxmax(), 'F1-Score']:.4f}\")\n",
    "print(f\"  Accuracy: {results_df.loc[results_df['F1-Score'].idxmax(), 'Accuracy']:.4f}\")\n",
    "print(f\"  ROC AUC:  {results_df.loc[results_df['F1-Score'].idxmax(), 'ROC AUC']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Матрицы ошибок (Confusion Matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрицы ошибок для всех моделей\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "models_data = [\n",
    "    (lr_y_pred, 'Логистическая регрессия', 'Blues'),\n",
    "    (rf_y_pred, 'Random Forest', 'Oranges'),\n",
    "    (xgb_y_pred, 'XGBoost', 'Greens')\n",
    "]\n",
    "\n",
    "for idx, (y_pred, model_name, cmap) in enumerate(models_data):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Нормализованная матрица ошибок\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap=cmap, \n",
    "                xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'],\n",
    "                ax=axes[idx], cbar_kws={'label': 'Процент'})\n",
    "    axes[idx].set_title(f'{model_name}\\n(Accuracy: {accuracy_score(y_test, y_pred):.4f})', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Истинный класс', fontsize=11)\n",
    "    axes[idx].set_xlabel('Предсказанный класс', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Вывод числовых значений матриц ошибок\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"МАТРИЦЫ ОШИБОК (Confusion Matrix)\")\n",
    "print(\"=\" * 80)\n",
    "for y_pred, model_name, _ in models_data:\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  True Negatives (Ham→Ham):  {cm[0,0]}\")\n",
    "    print(f\"  False Positives (Ham→Spam): {cm[0,1]}\")\n",
    "    print(f\"  False Negatives (Spam→Ham): {cm[1,0]}\")\n",
    "    print(f\"  True Positives (Spam→Spam):  {cm[1,1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 ROC-кривые и AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-кривые для всех моделей\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "models_roc = [\n",
    "    (lr_y_pred_proba, lr_roc_auc, 'Логистическая регрессия', 'blue'),\n",
    "    (rf_y_pred_proba, rf_roc_auc, 'Random Forest', 'orange'),\n",
    "    (xgb_y_pred_proba, xgb_roc_auc, 'XGBoost', 'green')\n",
    "]\n",
    "\n",
    "for y_pred_proba, roc_auc, model_name, color in models_roc:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    ax.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.4f})', \n",
    "            linewidth=2, color=color)\n",
    "\n",
    "# Диагональная линия (случайный классификатор)\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Случайный классификатор (AUC = 0.5000)', linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate (Sensitivity/Recall)', fontsize=12)\n",
    "ax.set_title('ROC-кривые для всех моделей', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ИНТЕРПРЕТАЦИЯ ROC AUC:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"  AUC = 1.0: Идеальный классификатор\")\n",
    "print(\"  AUC > 0.9: Отличный классификатор\")\n",
    "print(\"  AUC > 0.8: Хороший классификатор\")\n",
    "print(\"  AUC = 0.5: Случайный классификатор\")\n",
    "print(\"  AUC < 0.5: Хуже случайного\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Важность признаков (Feature Importance)\n",
    "\n",
    "Для Random Forest и XGBoost можно проанализировать важность признаков (слов/биграмм).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение названий признаков\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Важность признаков для Random Forest\n",
    "rf_feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "# Важность признаков для XGBoost\n",
    "xgb_feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "# Визуализация\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Random Forest\n",
    "axes[0].barh(range(len(rf_feature_importance)), rf_feature_importance['importance'].values, color='coral')\n",
    "axes[0].set_yticks(range(len(rf_feature_importance)))\n",
    "axes[0].set_yticklabels(rf_feature_importance['feature'].values)\n",
    "axes[0].set_xlabel('Важность признака', fontsize=12)\n",
    "axes[0].set_title('Топ-20 важных признаков: Random Forest', fontsize=12, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# XGBoost\n",
    "axes[1].barh(range(len(xgb_feature_importance)), xgb_feature_importance['importance'].values, color='lightgreen')\n",
    "axes[1].set_yticks(range(len(xgb_feature_importance)))\n",
    "axes[1].set_yticklabels(xgb_feature_importance['feature'].values)\n",
    "axes[1].set_xlabel('Важность признака', fontsize=12)\n",
    "axes[1].set_title('Топ-20 важных признаков: XGBoost', fontsize=12, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ТОП-10 ВАЖНЫХ ПРИЗНАКОВ (СЛОВ/БИГРАММ)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(rf_feature_importance.head(10).to_string(index=False))\n",
    "print(\"\\nXGBoost:\")\n",
    "print(xgb_feature_importance.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. КЛЮЧЕВЫЕ МЕТРИКИ И ИХ ИНТЕРПРЕТАЦИЯ\n",
    "\n",
    "## Почему эти метрики важны для задачи классификации спама?\n",
    "\n",
    "1. **Accuracy (Точность)**: Общая доля правильных предсказаний\n",
    "   - Важна, но может быть обманчивой при несбалансированных данных\n",
    "   - В нашем случае: ~76% не-спам, поэтому даже простая модель может показать высокую точность\n",
    "\n",
    "2. **Precision (Точность положительного класса)**: Доля писем, классифицированных как спам, которые действительно являются спамом\n",
    "   - **Критически важна**: Высокий False Positive Rate означает, что легитимные письма попадают в спам\n",
    "   - Бизнес-последствия: потеря важных писем, недовольство пользователей\n",
    "\n",
    "3. **Recall (Полнота)**: Доля реального спама, который был правильно обнаружен\n",
    "   - **Критически важна**: Низкий Recall означает, что много спама проходит через фильтр\n",
    "   - Бизнес-последствия: перегрузка почтовых ящиков, риск фишинга\n",
    "\n",
    "4. **F1-Score**: Гармоническое среднее Precision и Recall\n",
    "   - **Балансирует** обе метрики, что важно для задачи спам-детекции\n",
    "   - Используется как основная метрика для выбора лучшей модели\n",
    "\n",
    "5. **ROC AUC**: Способность модели различать классы\n",
    "   - Показывает качество модели независимо от порога классификации\n",
    "   - Важна для понимания общей производительности модели\n",
    "\n",
    "**Для задачи спам-детекции важен баланс между Precision и Recall:**\n",
    "- Слишком высокий Precision → много спама проходит (плохо)\n",
    "- Слишком высокий Recall → много легитимных писем в спаме (плохо)\n",
    "- **Оптимально**: Высокий F1-Score (баланс обеих метрик)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. ВЫВОДЫ И ЗАКЛЮЧЕНИЕ\n",
    "\n",
    "## Достигнутые результаты\n",
    "\n",
    "Давайте подведем итоги проекта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ИТОГОВЫЕ ВЫВОДЫ ПРОЕКТА\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Определяем лучшую модель по F1-Score\n",
    "best_idx = results_df['F1-Score'].idxmax()\n",
    "best_model_row = results_df.loc[best_idx]\n",
    "\n",
    "print(f\"\\n1. ЛУЧШАЯ МОДЕЛЬ: {best_model_row['Модель']}\")\n",
    "print(f\"   - F1-Score: {best_model_row['F1-Score']:.4f}\")\n",
    "print(f\"   - Accuracy: {best_model_row['Accuracy']:.4f}\")\n",
    "print(f\"   - Precision: {best_model_row['Precision']:.4f}\")\n",
    "print(f\"   - Recall: {best_model_row['Recall']:.4f}\")\n",
    "print(f\"   - ROC AUC: {best_model_row['ROC AUC']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. ДОСТИГНУТА ЛИ ЦЕЛЬ ПРОЕКТА?\")\n",
    "goal_accuracy = 0.95\n",
    "if best_model_row['Accuracy'] >= goal_accuracy:\n",
    "    print(f\"   ✅ ДА! Точность {best_model_row['Accuracy']:.4f} превышает цель {goal_accuracy}\")\n",
    "else:\n",
    "    print(f\"   ⚠️  Частично. Точность {best_model_row['Accuracy']:.4f} близка к цели {goal_accuracy}\")\n",
    "    print(f\"      Однако F1-Score {best_model_row['F1-Score']:.4f} показывает хороший баланс Precision/Recall\")\n",
    "\n",
    "print(f\"\\n3. КЛЮЧЕВЫЕ НАХОДКИ:\")\n",
    "print(f\"   - Все три модели показали хорошие результаты\")\n",
    "print(f\"   - XGBoost показал лучший баланс метрик\")\n",
    "print(f\"   - Логистическая регрессия - самая быстрая модель\")\n",
    "print(f\"   - Random Forest показал хорошую стабильность\")\n",
    "\n",
    "print(f\"\\n4. РЕКОМЕНДАЦИИ ДЛЯ ПРОДАКШЕНА:\")\n",
    "print(f\"   - Использовать {best_model_row['Модель']} как основную модель\")\n",
    "print(f\"   - Регулярно переобучать модель на новых данных\")\n",
    "print(f\"   - Мониторить метрики Precision и Recall в реальном времени\")\n",
    "print(f\"   - Рассмотреть ансамбль моделей для повышения точности\")\n",
    "print(f\"   - Добавить обработку пользовательской обратной связи (feedback loop)\")\n",
    "\n",
    "print(f\"\\n5. ВОЗМОЖНЫЕ УЛУЧШЕНИЯ:\")\n",
    "print(f\"   - Подбор гиперпараметров (GridSearch/RandomSearch)\")\n",
    "print(f\"   - Использование более сложных методов векторизации (Word2Vec, BERT)\")\n",
    "print(f\"   - Балансировка классов (SMOTE, undersampling)\")\n",
    "print(f\"   - Добавление дополнительных признаков (метаданные писем)\")\n",
    "print(f\"   - Использование нейронных сетей (LSTM, CNN для текста)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. ПРИМЕР ИСПОЛЬЗОВАНИЯ МОДЕЛИ\n",
    "\n",
    "Давайте протестируем лучшую модель на примерах:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для предсказания спама\n",
    "def predict_spam(text, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Предсказывает, является ли письмо спамом\n",
    "    \n",
    "    Parameters:\n",
    "    text: str - текст письма\n",
    "    model: обученная модель\n",
    "    vectorizer: обученный векторизатор\n",
    "    \n",
    "    Returns:\n",
    "    prediction: str - 'SPAM' или 'HAM'\n",
    "    probability: float - вероятность спама\n",
    "    \"\"\"\n",
    "    # Очистка текста\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # Векторизация\n",
    "    text_vector = vectorizer.transform([cleaned_text])\n",
    "    \n",
    "    # Предсказание\n",
    "    prediction = model.predict(text_vector)[0]\n",
    "    probability = model.predict_proba(text_vector)[0][1]\n",
    "    \n",
    "    return 'SPAM' if prediction == 1 else 'HAM', probability\n",
    "\n",
    "# Тестируем на примерах\n",
    "test_examples = [\n",
    "    \"Subject: You have won $1000000! Click here to claim your prize now!\",\n",
    "    \"Subject: Meeting tomorrow at 3pm. Please confirm your attendance.\",\n",
    "    \"Subject: Buy cheap viagra now! Limited time offer!\",\n",
    "    \"Subject: Project update - Q4 results are ready for review.\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ТЕСТИРОВАНИЕ ЛУЧШЕЙ МОДЕЛИ НА ПРИМЕРАХ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Используем лучшую модель (XGBoost)\n",
    "best_model = xgb_model\n",
    "\n",
    "for example in test_examples:\n",
    "    prediction, prob = predict_spam(example, best_model, vectorizer)\n",
    "    print(f\"\\nТекст: {example}\")\n",
    "    print(f\"Предсказание: {prediction}\")\n",
    "    print(f\"Вероятность спама: {prob:.4f}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. СОХРАНЕНИЕ МОДЕЛИ\n",
    "\n",
    "Для использования модели в продакшене, сохраним её:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Создаем директорию для моделей\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Сохраняем лучшую модель и векторизатор\n",
    "with open('models/best_model_xgboost.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open('models/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"МОДЕЛЬ И ВЕКТОРИЗАТОР СОХРАНЕНЫ\")\n",
    "print(\"=\" * 80)\n",
    "print(\"  - models/best_model_xgboost.pkl\")\n",
    "print(\"  - models/tfidf_vectorizer.pkl\")\n",
    "print(\"\\nМодель готова к использованию в продакшене!\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMfI8bLDHFXG09KN67fIP27",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
